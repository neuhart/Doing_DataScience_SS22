{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_enc = pd.read_csv('data\\encounter-events.csv')\n",
    "df_loit = pd.read_csv('data\\loitering-events.csv')\n",
    "df_ves = pd.read_csv('data/transshipment-vessels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Encounter Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This code:\n",
    "\n",
    "* removes all entries with duplicate values over all features\n",
    "* removes outliers in duration_hr column\n",
    "* transforms timestamps into floats and creates new time features as datetime objects\n",
    "* adds a support feature to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11458 encounterings left in the dataset\n"
     ]
    }
   ],
   "source": [
    "df_enc_mod = df_enc.copy()\n",
    "\n",
    "df_enc_mod = df_enc_mod.loc[df_enc_mod['duration_hr'] <= 65]  # remove outliers detected in the EDA file\n",
    "\n",
    "df_enc_mod.drop_duplicates(inplace = True)  # remove duplicates\n",
    "\n",
    "df_enc_mod = df_enc_mod[df_enc_mod['fishing_vessel_mmsi'].astype(int).astype(str).str.len() == 9]\n",
    "# remove all instances with wrong fishing_vessel_mmsi format\n",
    "\n",
    "print('{} encounterings left in the dataset'.format(df_enc_mod.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "df_enc_mod['start_time'] = pd.to_datetime(df_enc['start_time'])  # parse time objects\n",
    "df_enc_mod['end_time'] = pd.to_datetime(df_enc['end_time'])\n",
    "\n",
    "df_enc_mod['starting_timestamp'] = df_enc_mod['start_time'].apply(lambda x: x.timestamp()) # Changing format of timestamps from object to float\n",
    "df_enc_mod['ending_timestamp'] = df_enc_mod['end_time'].apply(lambda x: x.timestamp())\n",
    "\n",
    "# df_enc_mod.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "df_enc_mod['from_encounter'] = 1  # support variable need later after merging"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "# df_enc_mod.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loitering Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This code:\n",
    "\n",
    "* removes all entries with duplicate values over all features\n",
    "* remove outliers in total_even_duration column\n",
    "* Creates new feature and removes redundant features\n",
    "* transforms timestamps into floats and creates new time features as datetime objects\n",
    "* adds a support feature to the dataset\n",
    "* both transforms and renames features to those in the encounter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45919 loitering events left in the dataset\n"
     ]
    }
   ],
   "source": [
    "df_loit_mod =  df_loit.copy()\n",
    "\n",
    "df_loit_mod = df_loit_mod.loc[df_loit_mod['total_event_duration'] <= 200]  # remove outliers detected in the EDA file\n",
    "\n",
    "df_loit_mod.drop_duplicates(inplace = True)  # dropping duplicates\n",
    "\n",
    "print('{} loitering events left in the dataset'.format(df_loit_mod.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next step consists of creating mean variable for both latitude and longitude coordinates to match the format of the encounter dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "df_loit_mod['mean_latitude'] = (df_loit_mod['starting_latitude']+df_loit_mod['ending_latitude'])/2  # transforming locations to mean\n",
    "df_loit_mod['mean_longitude'] = (df_loit_mod['starting_longitude']+df_loit_mod['ending_longitude'])/2\n",
    "df_loit_mod.drop(columns=['starting_latitude','ending_latitude','starting_longitude', 'ending_longitude'], inplace=True)  # drop old columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we change the format of the dates columns to both a datetime and a timestamp (float) version"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "df_loit_mod['start_time'] = pd.to_datetime(df_loit['starting_timestamp'])  # Create new start time column with datetime format\n",
    "df_loit_mod['end_time'] = pd.to_datetime(df_loit['ending_timestamp'])\n",
    "\n",
    "df_loit_mod['starting_timestamp'] = df_loit_mod['start_time'].apply(lambda x: x.timestamp()) # Changing format of timestamps from object to float\n",
    "df_loit_mod['ending_timestamp'] = df_loit_mod['end_time'].apply(lambda x: x.timestamp())\n",
    "\n",
    "# df_loit_mod.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We rename the transshipment column make clear that it's a transshipment VESSEL attribute not one of a possible transshipment itself\n",
    "and rename the duration column to match the format of the encounter data set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "df_loit_mod.rename(columns ={'transshipment_mmsi':'transshipment_vessel_mmsi', 'total_event_duration':'duration_hr'}, inplace = True)\n",
    "\n",
    "df_loit_mod['from_encounter'] = 0  # support variable need later after merging"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "# df_loit_mod.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Vessel Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This code:\n",
    "\n",
    "* removes all entries with duplicate values in mmsi [Team Decision] to avoid issues with future joins over all datasets\n",
    "* removes all entries with NA or null values in the mmsi feature\n",
    "* transforms timestamps into datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ves_mod = df_ves.copy()\n",
    "\n",
    "df_ves_mod.dropna(inplace=True)\n",
    "# this is necessary to avoid weird (non sql) behavior from merge (nulls are recognized as keys!)\n",
    "\n",
    "df_ves_mod = df_ves_mod[df_ves_mod['mmsi'].astype(int).astype(str).str.len() == 9]  # get rid of vessel with wrong mmsi format\n",
    "\n",
    "df_ves_mod.drop_duplicates(subset = ['mmsi'], inplace = True)  # dropping duplicates in feature mmsi"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the dates, we want to have both times in datetime format and timestamps in float format"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "df_ves_mod['first_time'] = pd.to_datetime(df_ves_mod['first_timestamp'])  # Create new first time column with datetime format\n",
    "df_ves_mod['last_time'] = pd.to_datetime(df_ves_mod['last_timestamp'])\n",
    "\n",
    "df_ves_mod['first_timestamp'] = df_ves_mod['first_time'].apply(lambda x: x.timestamp())  # Change format from object to float\n",
    "df_ves_mod['last_timestamp'] = df_ves_mod['last_time'].apply(lambda x: x.timestamp())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "# df_ves_mod.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This code:\n",
    "\n",
    "* Aggregates(Stacks) Encounter and Loitering Datasets by keys and adds non matching features as additional columns\n",
    "* Reinserts the target feature as the first column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_agg = pd.concat([df_enc_mod,df_loit_mod], ignore_index=True)\n",
    "\n",
    "#setting support variable as first column:\n",
    "df_agg.insert(0, 'from_encounter',df_agg.pop('from_encounter'))\n",
    "\n",
    "# df_agg.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##  Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This code:\n",
    "\n",
    "* Merges the aggregated datasets with the vessel data on the key pair 'transshipment_vessel_mmsi' and 'mmsi'\n",
    "* This is sufficient because no fishing vessels are in the vessel dataset\n",
    "* manually adds a suffix of '_t' to all features originating from the vessel dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_clean_all = pd.merge(df_agg, df_ves_mod, how ='left', left_on ='transshipment_vessel_mmsi', right_on='mmsi')\n",
    "\n",
    "\n",
    "####Optional: add suffix to all added variables\n",
    "df_clean_all.rename(columns= { 'mmsi' : 'mmsi_t', 'shipname': 'shipname_t', 'callsign':'callsign_t', 'flag':'flag_t', 'imo': 'imo_t',\\\n",
    "     'first_timestamp': 'first_timestamp_t', 'last_timestamp':'last_timestamp_t'}, inplace = True)\n",
    "\n",
    "####This could be use to merge on fishing vessel, this is however not necessary in this context(No fishing vessels, only tranship)\n",
    "\n",
    "# df_clean_all = pd.merge(df_clean_all, df_ves_mod, how ='left', left_on ='fishing_vessel_mmsi', right_on='mmsi')\n",
    "# df_clean_all.rename(columns= { 'mmsi' : 'mmsi_f', 'shipname': 'shipname_f', 'callsign':'callsign_f', 'flag':'flag_f', 'imo': 'imo_f',\\\n",
    "#      'first_timestamp': 'first_timestamp_f', 'last_timestamp':'last_timestamp_f'}, inplace = True)\n",
    "\n",
    "df_clean_all.dropna(subset=['imo_t'],inplace=True) # some transshipment vessels apparently do not have an ímo code, those have to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50401 entries, 0 to 57376\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count  Dtype              \n",
      "---  ------                     --------------  -----              \n",
      " 0   from_encounter             50401 non-null  int64              \n",
      " 1   fishing_vessel_mmsi        10126 non-null  float64            \n",
      " 2   transshipment_vessel_mmsi  50401 non-null  int64              \n",
      " 3   start_time                 50401 non-null  datetime64[ns, UTC]\n",
      " 4   end_time                   50401 non-null  datetime64[ns, UTC]\n",
      " 5   mean_latitude              50401 non-null  float64            \n",
      " 6   mean_longitude             50401 non-null  float64            \n",
      " 7   duration_hr                50401 non-null  float64            \n",
      " 8   median_distance_km         10126 non-null  float64            \n",
      " 9   median_speed_knots         50401 non-null  float64            \n",
      " 10  starting_timestamp         50401 non-null  float64            \n",
      " 11  ending_timestamp           50401 non-null  float64            \n",
      " 12  mmsi_t                     50401 non-null  float64            \n",
      " 13  shipname_t                 50401 non-null  object             \n",
      " 14  callsign_t                 50401 non-null  object             \n",
      " 15  flag_t                     50401 non-null  object             \n",
      " 16  imo_t                      50401 non-null  float64            \n",
      " 17  first_timestamp_t          50401 non-null  float64            \n",
      " 18  last_timestamp_t           50401 non-null  float64            \n",
      " 19  first_time                 50401 non-null  datetime64[ns, UTC]\n",
      " 20  last_time                  50401 non-null  datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](4), float64(12), int64(2), object(3)\n",
      "memory usage: 8.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean_all.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "       from_encounter  fishing_vessel_mmsi  transshipment_vessel_mmsi  \\\n0                   1          416565000.0                  354240000   \n1                   1          412679190.0                  354240000   \n2                   1          440863000.0                  354240000   \n3                   1          416563000.0                  354240000   \n4                   1          441309000.0                  354240000   \n...               ...                  ...                        ...   \n57372               0                  NaN                  273349630   \n57373               0                  NaN                  273349630   \n57374               0                  NaN                  273349630   \n57375               0                  NaN                  273349630   \n57376               0                  NaN                  273349630   \n\n                     start_time                  end_time  mean_latitude  \\\n0     2016-11-18 14:30:00+00:00 2016-11-19 01:50:00+00:00     -17.039085   \n1     2016-12-11 14:50:00+00:00 2016-12-11 19:50:00+00:00     -20.269608   \n2     2017-06-13 12:50:00+00:00 2017-06-15 01:20:00+00:00     -62.640767   \n3     2016-11-15 11:30:00+00:00 2016-11-16 04:00:00+00:00     -17.046586   \n4     2017-05-19 00:40:00+00:00 2017-05-19 20:50:00+00:00     -46.627878   \n...                         ...                       ...            ...   \n57372 2017-09-29 07:55:39+00:00 2017-09-29 22:49:11+00:00      51.945812   \n57373 2016-11-19 08:08:13+00:00 2016-11-20 00:58:25+00:00      48.793993   \n57374 2014-06-27 01:32:36+00:00 2014-06-28 01:21:20+00:00      58.224653   \n57375 2016-10-29 17:22:12+00:00 2016-10-30 21:12:23+00:00      57.452946   \n57376 2015-07-17 18:14:48+00:00 2015-07-19 01:59:49+00:00      57.563541   \n\n       mean_longitude  duration_hr  median_distance_km  median_speed_knots  \\\n0          -79.063725    11.333333            0.038188            0.585402   \n1          -79.244953     5.000000            0.020033            0.575663   \n2          -60.690240    36.500000            0.054992            0.019775   \n3          -79.061923    16.500000            0.036427            1.023917   \n4          -60.554922    20.166667            0.034053            0.544031   \n...               ...          ...                 ...                 ...   \n57372      155.562330    16.982917                 NaN            1.092219   \n57373      141.242218    17.053056                 NaN            0.764958   \n57374      153.102242    25.157083                 NaN            0.560717   \n57375      150.443527    29.134444                 NaN            0.545175   \n57376      151.103195    34.060139                 NaN            0.456930   \n\n       ...  ending_timestamp       mmsi_t      shipname_t callsign_t flag_t  \\\n0      ...      1.479520e+09  354240000.0  CRYSTAL REEFER      3FFY5    PAN   \n1      ...      1.481486e+09  354240000.0  CRYSTAL REEFER      3FFY5    PAN   \n2      ...      1.497490e+09  354240000.0  CRYSTAL REEFER      3FFY5    PAN   \n3      ...      1.479269e+09  354240000.0  CRYSTAL REEFER      3FFY5    PAN   \n4      ...      1.495227e+09  354240000.0  CRYSTAL REEFER      3FFY5    PAN   \n...    ...               ...          ...             ...        ...    ...   \n57372  ...      1.506725e+09  273349630.0          ZODIAK      UBFG9    RUS   \n57373  ...      1.479604e+09  273349630.0          ZODIAK      UBFG9    RUS   \n57374  ...      1.403918e+09  273349630.0          ZODIAK      UBFG9    RUS   \n57375  ...      1.477862e+09  273349630.0          ZODIAK      UBFG9    RUS   \n57376  ...      1.437271e+09  273349630.0          ZODIAK      UBFG9    RUS   \n\n           imo_t  first_timestamp_t  last_timestamp_t  \\\n0      9017276.0       1.422748e+09      1.489109e+09   \n1      9017276.0       1.422748e+09      1.489109e+09   \n2      9017276.0       1.422748e+09      1.489109e+09   \n3      9017276.0       1.422748e+09      1.489109e+09   \n4      9017276.0       1.422748e+09      1.489109e+09   \n...          ...                ...               ...   \n57372  8712300.0       1.328268e+09      1.530318e+09   \n57373  8712300.0       1.328268e+09      1.530318e+09   \n57374  8712300.0       1.328268e+09      1.530318e+09   \n57375  8712300.0       1.328268e+09      1.530318e+09   \n57376  8712300.0       1.328268e+09      1.530318e+09   \n\n                     first_time                 last_time  \n0     2015-01-31 23:43:15+00:00 2017-03-10 01:21:55+00:00  \n1     2015-01-31 23:43:15+00:00 2017-03-10 01:21:55+00:00  \n2     2015-01-31 23:43:15+00:00 2017-03-10 01:21:55+00:00  \n3     2015-01-31 23:43:15+00:00 2017-03-10 01:21:55+00:00  \n4     2015-01-31 23:43:15+00:00 2017-03-10 01:21:55+00:00  \n...                         ...                       ...  \n57372 2012-02-03 11:26:34+00:00 2018-06-30 00:13:21+00:00  \n57373 2012-02-03 11:26:34+00:00 2018-06-30 00:13:21+00:00  \n57374 2012-02-03 11:26:34+00:00 2018-06-30 00:13:21+00:00  \n57375 2012-02-03 11:26:34+00:00 2018-06-30 00:13:21+00:00  \n57376 2012-02-03 11:26:34+00:00 2018-06-30 00:13:21+00:00  \n\n[50401 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>from_encounter</th>\n      <th>fishing_vessel_mmsi</th>\n      <th>transshipment_vessel_mmsi</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>mean_latitude</th>\n      <th>mean_longitude</th>\n      <th>duration_hr</th>\n      <th>median_distance_km</th>\n      <th>median_speed_knots</th>\n      <th>...</th>\n      <th>ending_timestamp</th>\n      <th>mmsi_t</th>\n      <th>shipname_t</th>\n      <th>callsign_t</th>\n      <th>flag_t</th>\n      <th>imo_t</th>\n      <th>first_timestamp_t</th>\n      <th>last_timestamp_t</th>\n      <th>first_time</th>\n      <th>last_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>416565000.0</td>\n      <td>354240000</td>\n      <td>2016-11-18 14:30:00+00:00</td>\n      <td>2016-11-19 01:50:00+00:00</td>\n      <td>-17.039085</td>\n      <td>-79.063725</td>\n      <td>11.333333</td>\n      <td>0.038188</td>\n      <td>0.585402</td>\n      <td>...</td>\n      <td>1.479520e+09</td>\n      <td>354240000.0</td>\n      <td>CRYSTAL REEFER</td>\n      <td>3FFY5</td>\n      <td>PAN</td>\n      <td>9017276.0</td>\n      <td>1.422748e+09</td>\n      <td>1.489109e+09</td>\n      <td>2015-01-31 23:43:15+00:00</td>\n      <td>2017-03-10 01:21:55+00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>412679190.0</td>\n      <td>354240000</td>\n      <td>2016-12-11 14:50:00+00:00</td>\n      <td>2016-12-11 19:50:00+00:00</td>\n      <td>-20.269608</td>\n      <td>-79.244953</td>\n      <td>5.000000</td>\n      <td>0.020033</td>\n      <td>0.575663</td>\n      <td>...</td>\n      <td>1.481486e+09</td>\n      <td>354240000.0</td>\n      <td>CRYSTAL REEFER</td>\n      <td>3FFY5</td>\n      <td>PAN</td>\n      <td>9017276.0</td>\n      <td>1.422748e+09</td>\n      <td>1.489109e+09</td>\n      <td>2015-01-31 23:43:15+00:00</td>\n      <td>2017-03-10 01:21:55+00:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>440863000.0</td>\n      <td>354240000</td>\n      <td>2017-06-13 12:50:00+00:00</td>\n      <td>2017-06-15 01:20:00+00:00</td>\n      <td>-62.640767</td>\n      <td>-60.690240</td>\n      <td>36.500000</td>\n      <td>0.054992</td>\n      <td>0.019775</td>\n      <td>...</td>\n      <td>1.497490e+09</td>\n      <td>354240000.0</td>\n      <td>CRYSTAL REEFER</td>\n      <td>3FFY5</td>\n      <td>PAN</td>\n      <td>9017276.0</td>\n      <td>1.422748e+09</td>\n      <td>1.489109e+09</td>\n      <td>2015-01-31 23:43:15+00:00</td>\n      <td>2017-03-10 01:21:55+00:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>416563000.0</td>\n      <td>354240000</td>\n      <td>2016-11-15 11:30:00+00:00</td>\n      <td>2016-11-16 04:00:00+00:00</td>\n      <td>-17.046586</td>\n      <td>-79.061923</td>\n      <td>16.500000</td>\n      <td>0.036427</td>\n      <td>1.023917</td>\n      <td>...</td>\n      <td>1.479269e+09</td>\n      <td>354240000.0</td>\n      <td>CRYSTAL REEFER</td>\n      <td>3FFY5</td>\n      <td>PAN</td>\n      <td>9017276.0</td>\n      <td>1.422748e+09</td>\n      <td>1.489109e+09</td>\n      <td>2015-01-31 23:43:15+00:00</td>\n      <td>2017-03-10 01:21:55+00:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>441309000.0</td>\n      <td>354240000</td>\n      <td>2017-05-19 00:40:00+00:00</td>\n      <td>2017-05-19 20:50:00+00:00</td>\n      <td>-46.627878</td>\n      <td>-60.554922</td>\n      <td>20.166667</td>\n      <td>0.034053</td>\n      <td>0.544031</td>\n      <td>...</td>\n      <td>1.495227e+09</td>\n      <td>354240000.0</td>\n      <td>CRYSTAL REEFER</td>\n      <td>3FFY5</td>\n      <td>PAN</td>\n      <td>9017276.0</td>\n      <td>1.422748e+09</td>\n      <td>1.489109e+09</td>\n      <td>2015-01-31 23:43:15+00:00</td>\n      <td>2017-03-10 01:21:55+00:00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57372</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>273349630</td>\n      <td>2017-09-29 07:55:39+00:00</td>\n      <td>2017-09-29 22:49:11+00:00</td>\n      <td>51.945812</td>\n      <td>155.562330</td>\n      <td>16.982917</td>\n      <td>NaN</td>\n      <td>1.092219</td>\n      <td>...</td>\n      <td>1.506725e+09</td>\n      <td>273349630.0</td>\n      <td>ZODIAK</td>\n      <td>UBFG9</td>\n      <td>RUS</td>\n      <td>8712300.0</td>\n      <td>1.328268e+09</td>\n      <td>1.530318e+09</td>\n      <td>2012-02-03 11:26:34+00:00</td>\n      <td>2018-06-30 00:13:21+00:00</td>\n    </tr>\n    <tr>\n      <th>57373</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>273349630</td>\n      <td>2016-11-19 08:08:13+00:00</td>\n      <td>2016-11-20 00:58:25+00:00</td>\n      <td>48.793993</td>\n      <td>141.242218</td>\n      <td>17.053056</td>\n      <td>NaN</td>\n      <td>0.764958</td>\n      <td>...</td>\n      <td>1.479604e+09</td>\n      <td>273349630.0</td>\n      <td>ZODIAK</td>\n      <td>UBFG9</td>\n      <td>RUS</td>\n      <td>8712300.0</td>\n      <td>1.328268e+09</td>\n      <td>1.530318e+09</td>\n      <td>2012-02-03 11:26:34+00:00</td>\n      <td>2018-06-30 00:13:21+00:00</td>\n    </tr>\n    <tr>\n      <th>57374</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>273349630</td>\n      <td>2014-06-27 01:32:36+00:00</td>\n      <td>2014-06-28 01:21:20+00:00</td>\n      <td>58.224653</td>\n      <td>153.102242</td>\n      <td>25.157083</td>\n      <td>NaN</td>\n      <td>0.560717</td>\n      <td>...</td>\n      <td>1.403918e+09</td>\n      <td>273349630.0</td>\n      <td>ZODIAK</td>\n      <td>UBFG9</td>\n      <td>RUS</td>\n      <td>8712300.0</td>\n      <td>1.328268e+09</td>\n      <td>1.530318e+09</td>\n      <td>2012-02-03 11:26:34+00:00</td>\n      <td>2018-06-30 00:13:21+00:00</td>\n    </tr>\n    <tr>\n      <th>57375</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>273349630</td>\n      <td>2016-10-29 17:22:12+00:00</td>\n      <td>2016-10-30 21:12:23+00:00</td>\n      <td>57.452946</td>\n      <td>150.443527</td>\n      <td>29.134444</td>\n      <td>NaN</td>\n      <td>0.545175</td>\n      <td>...</td>\n      <td>1.477862e+09</td>\n      <td>273349630.0</td>\n      <td>ZODIAK</td>\n      <td>UBFG9</td>\n      <td>RUS</td>\n      <td>8712300.0</td>\n      <td>1.328268e+09</td>\n      <td>1.530318e+09</td>\n      <td>2012-02-03 11:26:34+00:00</td>\n      <td>2018-06-30 00:13:21+00:00</td>\n    </tr>\n    <tr>\n      <th>57376</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>273349630</td>\n      <td>2015-07-17 18:14:48+00:00</td>\n      <td>2015-07-19 01:59:49+00:00</td>\n      <td>57.563541</td>\n      <td>151.103195</td>\n      <td>34.060139</td>\n      <td>NaN</td>\n      <td>0.456930</td>\n      <td>...</td>\n      <td>1.437271e+09</td>\n      <td>273349630.0</td>\n      <td>ZODIAK</td>\n      <td>UBFG9</td>\n      <td>RUS</td>\n      <td>8712300.0</td>\n      <td>1.328268e+09</td>\n      <td>1.530318e+09</td>\n      <td>2012-02-03 11:26:34+00:00</td>\n      <td>2018-06-30 00:13:21+00:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>50401 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_all"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output\n",
    "Now we are saving the dataset that we are going to use for clustering in the next step."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "df_clean_all.to_csv('data/cleaned_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2525ca78ad5a0849c517621bcdb6f6a8e4e6329015be4e411079257f1dd0fa01"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}